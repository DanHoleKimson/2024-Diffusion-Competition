{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import (Dataset, DataLoader)\n",
    "\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 CLASSES의 이름은 다운 받은 폴더의 이름이 일치해야 합니다. ex) data/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우리가 분류할 4개의 클래스\n",
    "#CLASSES = [ 'MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented' ]\n",
    "classes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "config들."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    NUM_DEVICES = torch.cuda.device_count()\n",
    "    NUM_WORKERS = os.cpu_count()\n",
    "    NUM_CLASSES = 4\n",
    "    EPOCHS = 16\n",
    "    BATCH_SIZE = (\n",
    "        32 if torch.cuda.device_count() < 2 \n",
    "        else (32 * torch.cuda.device_count())\n",
    "    )\n",
    "    LR = 0.001\n",
    "    APPLY_SHUFFLE = True\n",
    "    SEED = 768\n",
    "    HEIGHT = 224\n",
    "    WIDTH = 224\n",
    "    CHANNELS = 3\n",
    "    IMAGE_SIZE = (224, 224, 3)\n",
    "    \n",
    "    # Define paths\n",
    "    DATASET_PATH = \"/kaggle/input/brain-tumor-mri-dataset/\"\n",
    "    TRAIN_PATH = '/kaggle/input/brain-tumor-mri-dataset/Training/'\n",
    "    TEST_PATH = '/kaggle/input/brain-tumor-mri-dataset/Testing/'\n",
    "    \n",
    "# Mute warnings\n",
    "warnings.filterwarnings(\"ignore\", \"is_categorical_dtype\")\n",
    "warnings.filterwarnings(\"ignore\", \"use_inf_as_na\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습에 필요한 상수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 학습에 필요한 상수들을 정의 합니다.\n",
    "IMG_SHAPE = (224, 224, 3)\n",
    "LEARNING_RATE = 2e-5\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "\n",
    "# 각 이미지의 기본 주소\n",
    "BASE_PATH = './drive/MyDrive/Colab Notebooks/data/'\n",
    "images_dir = Path(BASE_PATH).expanduser()\n",
    "print(images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내 드라이브 파일 마운트하고, 폴더 정보 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 모델 학습에 사용할 데이터 정보를 설정합니다.\n",
    "class_list = []\n",
    "num_list = []\n",
    "\n",
    "# IMAGE_BASE_PATH = './data/'\n",
    "train_path = BASE_PATH + 'train/'\n",
    "for folder in os.listdir(train_path):\n",
    "    classes.append(folder)\n",
    "    folder_size = len(os.listdir(train_path+folder))\n",
    "    class_list.append(folder)\n",
    "    num_list.append(folder_size)\n",
    "\n",
    "voc_s = pd.Series(num_list,index=class_list)\n",
    "voc_s.sort_values().plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "print(voc_s.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 검증에 사용할 데이터 내용 입니다.\n",
    "\n",
    "class_list = []\n",
    "num_list = []\n",
    "\n",
    "#IMAGE_BASE_PATH = './data/'\n",
    "valid_path = BASE_PATH + 'test/'\n",
    "for folder in os.listdir(valid_path):\n",
    "    folder_size = len(os.listdir(valid_path+folder))\n",
    "    # print('{:<15} : {}'.format(folder,folder_size))\n",
    "    class_list.append(folder)\n",
    "    num_list.append(folder_size)\n",
    "\n",
    "voc_s = pd.Series(num_list,index=class_list)\n",
    "voc_s.sort_values().plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "print(voc_s.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = glob.glob(f\"{CFG.TRAIN_PATH}**/*.jpg\")\n",
    "test_images = glob.glob(f\"{CFG.TEST_PATH}**/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labels(image_paths):\n",
    "    return [(_.split('/')[-2:][0]).replace('-', '_') for _ in image_paths]\n",
    "\n",
    "def build_df(image_paths, labels):\n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'image_path': image_paths,\n",
    "        'label': generate_labels(labels)\n",
    "    })\n",
    "    \n",
    "    # Return df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the DataFrames\n",
    "# train_df = build_df(train_images, generate_labels(train_images))\n",
    "train_df = build_df(train_images, train_images)\n",
    "# test_df = build_df(test_images, generate_labels(test_images))\n",
    "test_df = build_df(test_images, test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train/Val split with Training Set\n",
    "train_split_idx, val_split_idx, _, _ = (\n",
    "    train_test_split(\n",
    "        train_df.index, \n",
    "        train_df.label, \n",
    "        test_size=0.20,\n",
    "        stratify=train_df.label,\n",
    "        random_state=CFG.SEED\n",
    "    )\n",
    ")\n",
    "\n",
    "# Get training and remaining data\n",
    "train_new_df = train_df.iloc[train_split_idx].reset_index(drop=True)\n",
    "val_df = train_df.iloc[val_split_idx].reset_index(drop=True)\n",
    "\n",
    "# View shapes\n",
    "# train_new_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions for display. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load(image_path, as_tensor=True):\n",
    "    # Read and decode an image file to a uint8 tensor\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    if as_tensor:\n",
    "        converter = transforms.Compose([\n",
    "            transforms.ToTensor(), \n",
    "            transforms.Grayscale()\n",
    "        ])\n",
    "        return converter(image)\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "\n",
    "def view_sample(image, label, color_map='rgb', fig_size=(8, 10)):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    \n",
    "    if color_map=='rgb':\n",
    "        plt.imshow(image)\n",
    "    else:\n",
    "        plt.imshow(image, cmap=color_map)\n",
    "    \n",
    "    plt.title(f'Label: {label}', fontsize=16)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Learning 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetV2Model(nn.Module):\n",
    "    def __init__(self, backbone_model, name='efficientnet-v2-large', \n",
    "                 num_classes=CFG.NUM_CLASSES, device=CFG.DEVICE):\n",
    "        super(EfficientNetV2Model, self).__init__()\n",
    "        \n",
    "        self.backbone_model = backbone_model\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        self.name = name\n",
    "        \n",
    "        classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.2, inplace=True), \n",
    "            nn.Linear(in_features=1280, out_features=256, bias=True),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=0.2, inplace=True),\n",
    "            nn.Linear(in_features=256, out_features=num_classes, bias=False)\n",
    "        ).to(device)\n",
    "        \n",
    "        self._set_classifier(classifier)\n",
    "        \n",
    "    def _set_classifier(self, classifier:nn.Module) -> None:\n",
    "        self.backbone_model.classifier = classifier\n",
    "    \n",
    "    def forward(self, image):\n",
    "        return self.backbone_model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_effiecientnetv2_model(\n",
    "    device: torch.device=CFG.NUM_CLASSES) -> nn.Module:\n",
    "    # Set the manual seeds\n",
    "    torch.manual_seed(CFG.SEED)\n",
    "    torch.cuda.manual_seed(CFG.SEED)\n",
    "\n",
    "    # Get model weights\n",
    "    model_weights = (\n",
    "        torchvision.models.EfficientNet_V2_L_Weights.DEFAULT)\n",
    "    \n",
    "    # Get model and push to device\n",
    "    model = (\n",
    "        torchvision.models.efficientnet_v2_l(\n",
    "            weights=model_weights\n",
    "        )\n",
    "    ).to(device) \n",
    "    \n",
    "    # Freeze Model Parameters\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get EfficientNet v2 model\n",
    "backbone_model = get_effiecientnetv2_model(CFG.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnetv2_params = {\n",
    "    'backbone_model'    : backbone_model,\n",
    "    'name'              : 'efficientnet-v2-large',\n",
    "    'device'            : CFG.DEVICE\n",
    "}\n",
    "\n",
    "# Generate Model\n",
    "efficientnet_model = EfficientNetV2Model(**efficientnetv2_params)\n",
    "\n",
    "# If using GPU T4 x2 setup, use this:\n",
    "if CFG.NUM_DEVICES > 1:\n",
    "    efficientnet_model = nn.DataParallel(efficientnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View model summary\n",
    "summary(\n",
    "    model=efficientnet_model, \n",
    "    input_size=(CFG.BATCH_SIZE, CFG.CHANNELS, CFG.WIDTH, CFG.HEIGHT),\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- define Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Function\n",
    "loss_fn = nn.CrossEntropyLoss(\n",
    "    label_smoothing=0.1\n",
    ")\n",
    "\n",
    "# Define Optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    efficientnet_model.parameters(),\n",
    "    lr=CFG.LR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Epoch Execution (Train Step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_epoch(\n",
    "    model:torch.nn.Module,\n",
    "    dataloader:torch.utils.data.DataLoader,\n",
    "    optimizer:torch.optim.Optimizer,\n",
    "    loss_fn:torch.nn.Module,\n",
    "    device:torch.device) -> Tuple[float, float]:\n",
    "    \n",
    "    # Set model into training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize train loss & accuracy\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    # Execute training loop over train dataloader\n",
    "    for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
    "        # Load data onto target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Feed-forward and compute metrics\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item() \n",
    "        \n",
    "        # Reset Gradients & Backpropagate Loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Model Gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute Batch Metrics\n",
    "        predicted_class = torch.argmax(\n",
    "            torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (predicted_class == y).sum().item() / len(y_pred)\n",
    "        \n",
    "    # Compute Step Metrics\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    \n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Evaluation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    model:torch.nn.Module,\n",
    "    dataloader:torch.utils.data.DataLoader,\n",
    "    loss_fn:torch.nn.Module,\n",
    "    device:torch.device) -> Tuple[float, float]:\n",
    "    \n",
    "    # Set model into eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize eval loss & accuracy\n",
    "    eval_loss, eval_acc = 0, 0\n",
    "    \n",
    "    # Active inferene context manager\n",
    "    with torch.inference_mode():\n",
    "        # Execute eval loop over dataloader\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # Load data onto target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Feed-forward and compute metrics\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            eval_loss += loss.item() \n",
    "\n",
    "            # Compute Batch Metrics\n",
    "            predicted_class = torch.argmax(\n",
    "                torch.softmax(y_pred, dim=1), dim=1)\n",
    "            eval_acc += (predicted_class == y).sum().item() / len(y_pred)\n",
    "        \n",
    "    # Compute Step Metrics\n",
    "    eval_loss = eval_loss / len(dataloader)\n",
    "    eval_acc = eval_acc / len(dataloader)\n",
    "    \n",
    "    return eval_loss, eval_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model:torch.nn.Module,\n",
    "    train_dataloader:torch.utils.data.DataLoader,\n",
    "    eval_dataloader:torch.utils.data.DataLoader,\n",
    "    optimizer:torch.optim.Optimizer,\n",
    "    loss_fn:torch.nn.Module,\n",
    "    epochs:int,\n",
    "    device:torch.device) -> Dict[str, List]:\n",
    "    \n",
    "    # Initialize training session\n",
    "    session = {\n",
    "        'loss'          : [],\n",
    "        'accuracy'      : [],\n",
    "        'eval_loss'     : [],\n",
    "        'eval_accuaracy': []\n",
    "    }\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Execute Epoch\n",
    "        print(f'\\nEpoch {epoch + 1}/{epochs}')\n",
    "        train_loss, train_acc = execute_epoch(\n",
    "            model, \n",
    "            train_dataloader, \n",
    "            optimizer, \n",
    "            loss_fn, \n",
    "            device\n",
    "        )\n",
    "        \n",
    "        # Evaluate Model\n",
    "        eval_loss, eval_acc = evaluate(\n",
    "            model, \n",
    "            eval_dataloader,\n",
    "            loss_fn, \n",
    "            device\n",
    "        )\n",
    "        \n",
    "        # Log Epoch Metrics\n",
    "        print(f'loss: {train_loss:.4f} - acc: {train_acc:.4f} - eval_loss: {eval_loss:.4f} - eval_acc: {eval_acc:.4f}')\n",
    "        \n",
    "        # Record Epoch Metrics\n",
    "        session['loss'].append(train_loss)\n",
    "        session['accuracy'].append(train_acc)\n",
    "        session['eval_loss'].append(eval_loss)\n",
    "        session['eval_accuaracy'].append(eval_acc)\n",
    "        \n",
    "    # Return Session Metrics\n",
    "    return session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train EfficientNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model \n",
    "print('Training EfficientNet Model')\n",
    "print(f'Train on {len(train_new_df)} samples, validate on {len(val_df)} samples.')\n",
    "print('----------------------------------')\n",
    "\n",
    "efficientnet_session_config = {\n",
    "    'model'               : efficientnet_model,\n",
    "    'train_dataloader'    : train_loader,\n",
    "    'eval_dataloader'     : val_loader,\n",
    "    'optimizer'           : optimizer,\n",
    "    'loss_fn'             : loss_fn,\n",
    "    'epochs'              : CFG.EPOCHS,\n",
    "    'device'              : CFG.DEVICE\n",
    "}\n",
    "\n",
    "efficientnet_session_history = train(**efficientnet_session_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hackaton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
